Model,Training Score,Testing Score
"Logistic Regression (Base Scikit-Learn, no parameter update):",0.986,0.753
Logistic Regression (max_iter = 1),0.86,0.625
Logistic Regression (max_iter = 50),0.986,0.753
Logistic Regression (C=0.5),0.986,0.753
Decision Tree (max_depth = 3),0.976,0.754
Decision Tree (min_samples_leaf = 20),0.996,0.756
Decision Tree (max_depth = 1),0.907,0.622
"Decision Tree(max_depth = 3, max_features = 3)",0.7302,0.653
"Decision Tree(max_depth = 3, max_features = 4)",0.8716,0.682
"Decision Tree(max_depth = 4, max_features = 3)",0.8585,0.66
"Decision Tree(max_depth = 3, max_features = 2)",0.683,0.525
"Logistic Regression(C=0.5), dropped grammar_errors column",0.9645,0.51
"Decision Tree (min_samples_leaf = 20), dropped grammar_errors column",0.9841,0.478
Random Forest (base model),1,0.769
Catboost (Gradient Boosting),0.9903,0.763
Detector,0.9231,0.789
ANN,0.9866,0.742
Logistic Regression + TFIDF,0.998,0.79
Decision Tree(min_samples_leaf=20) + TFIDF,0.985,0.668
Random Forest (base from Sklearn) + TFIDF,1,0.743
"CatBoost (iterations=100,learning_rate=0.03) + TFIDF",0.988,0.738
Bidirectional LSTM,0.9999,0.74
Bidirectional LSTM with Constraints like Dropout,0.961,0.678
"Bidirectional LSTM (embed dim 250, hidden dim 128, dropout 0.3 )",0.9995,0.771
"2 Layer Bidirectional LSTM (embed dim 250, hidden dim 128, dropout 0.3)",0.9999,0.791
"Transformer (d_model = 512, nheads=8, 2 layers, trained for 10 epochs)",0.992,0.782
"Transformer (d_model = 512, nheads=8, 2 layers, trained for 30 epochs)",0.999,0.81