Model,Training Score,Testing Score
"Transformer (d_model = 512, nheads=8, 2 layers, trained for 30 epochs) + (Catboost (iterations=5000, learning_rate=0.03) + TFIDF (3-5 ngrams))",0.9998,0.835
"Catboost (iterations=5000, learning_rate=0.03) + TFIDF (3-5 ngrams)",0.999,0.814
"Transformer (d_model = 512, nheads=8, 2 layers, trained for 30 epochs)",0.999,0.81
"Catboost (iterations=5000, learning_rate=0.03) + TFIDF (3-5 ngrams) + Custom Features",0.9996,0.796
"2 Layer Bidirectional LSTM (embed dim 250, hidden dim 128, dropout 0.3)",0.9999,0.791
Logistic Regression + TFIDF,0.998,0.79
Detector,0.9231,0.789
"Transformer (d_model = 512, nheads=8, 2 layers, trained for 10 epochs)",0.992,0.782
"Bidirectional LSTM (embed dim 250, hidden dim 128, dropout 0.3 )",0.9995,0.771
Random Forest (base model),1,0.769
Catboost (Gradient Boosting),0.9903,0.763
Decision Tree (min_samples_leaf = 20),0.996,0.756
Decision Tree (max_depth = 3),0.976,0.754
"Logistic Regression (Base Scikit-Learn, no parameter update):",0.986,0.753
Logistic Regression (max_iter = 50),0.986,0.753
Logistic Regression (C=0.5),0.986,0.753
Random Forest (base from Sklearn) + TFIDF,1,0.743
ANN,0.9866,0.742
Bidirectional LSTM,0.9999,0.74
"CatBoost (iterations=100,learning_rate=0.03) + TFIDF",0.988,0.738
"Decision Tree(max_depth = 3, max_features = 4)",0.8716,0.682
Bidirectional LSTM with Constraints like Dropout,0.961,0.678
Decision Tree(min_samples_leaf=20) + TFIDF,0.985,0.668
"Decision Tree(max_depth = 4, max_features = 3)",0.8585,0.66
"Decision Tree(max_depth = 3, max_features = 3)",0.7302,0.653
Logistic Regression (max_iter = 1),0.86,0.625
Decision Tree (max_depth = 1),0.907,0.622
"Decision Tree(max_depth = 3, max_features = 2)",0.683,0.525
"Logistic Regression(C=0.5), dropped grammar_errors column",0.9645,0.51
"Decision Tree (min_samples_leaf = 20), dropped grammar_errors column",0.9841,0.478