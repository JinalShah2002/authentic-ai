{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency Inverse Document Frequency (TFIDF)\n",
    "\n",
    "For the feature set I made, it was clear that the models that utilized those features overfit heavily and had a \"performance cap\" of 0.77. To rank up in the leaderboard, it is clear that I may need to go away from those features and try to utilize the physical words in the essays.\n",
    "\n",
    "Many high scoring solutions utilize TFIDF. The TFIDF of a word is the following:  \n",
    "\n",
    "**TFIDF_word = Term Frequency * log (number of documents / document frequency)**  \n",
    "\n",
    "Where term frequency is the number of times a word appears / total words in a document and document frequency = the number of documents with the word. \n",
    "\n",
    "It seems TFIDF is a very powerful tool to utilize in NLP problems, and one can utilize it to get a quick solution. I note this as a learning for future projects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I think art edukation is super impotent for kids. Some peoples might say its not that impotent but I disagree. Arts helps kids with theyre imagination and creativity. Like for example when we do art projects in skool it helps me think outside the box and come up with new ideas. Also it helps with theyre self esteem and confidence. When we perform in frunt of the skool or in a play it helps us not be affraid to speak in frunt of peoples. Also art is a way to express our selfs and show how we feel. Like when Im feeling sad or mad I can draw a picshure that shows how I feel and it helps me feel beter.\\n\\nAnother thing that sucks is that some skools are cutting art programs cuz they think its not that impotent. This is super wrong cuz art is a way for kids to express theyre selfs and it helps them develop theyre brain. It also helps them be more creative and have better imagination. Without art edukation kids will be bornt and not have as much fun in skool.\\n\\nI also think that art edukation should be a requirement in skool. Just like math and english, art is impotent too. It helps us with our problem solving skills and it helps us be more critical thinkers. Also it helps us understand other subjects better like history and culture. Like when we learn about diffrent cultures throught art it helps us understand theyre way of life and theyre belifs.\\n\\nIn conclusion art edukation is super impotent for kids. It helps us with our imagination, self esteem, confidence, and it helps us express our selfs. It also helps us develop our brain and be more creative. Art should be a requirement in skool cuz its impotent for a well-rounded edukation.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the essays\n",
    "essays = pd.read_csv('../prepared_training_set.csv')['essay'].tolist()\n",
    "labels = pd.read_csv('../prepared_training_set.csv')['LLM_written'].values\n",
    "essays[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3),norm=None,max_features=500,min_df=100,max_df=0.8)\n",
    "\n",
    "# Fitting it to the essays\n",
    "X = vectorizer.fit_transform(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>able to</th>\n",
       "      <th>about</th>\n",
       "      <th>about the</th>\n",
       "      <th>activities</th>\n",
       "      <th>activity</th>\n",
       "      <th>advice</th>\n",
       "      <th>after</th>\n",
       "      <th>air</th>\n",
       "      <th>all</th>\n",
       "      <th>all the</th>\n",
       "      <th>also</th>\n",
       "      <th>always</th>\n",
       "      <th>am</th>\n",
       "      <th>an</th>\n",
       "      <th>and it</th>\n",
       "      <th>and that</th>\n",
       "      <th>and the</th>\n",
       "      <th>and they</th>\n",
       "      <th>animals</th>\n",
       "      <th>another</th>\n",
       "      <th>any</th>\n",
       "      <th>are not</th>\n",
       "      <th>around</th>\n",
       "      <th>article</th>\n",
       "      <th>as</th>\n",
       "      <th>as the</th>\n",
       "      <th>as well</th>\n",
       "      <th>ask</th>\n",
       "      <th>at</th>\n",
       "      <th>at home</th>\n",
       "      <th>at the</th>\n",
       "      <th>attention</th>\n",
       "      <th>author</th>\n",
       "      <th>average</th>\n",
       "      <th>away</th>\n",
       "      <th>back</th>\n",
       "      <th>bad</th>\n",
       "      <th>based</th>\n",
       "      <th>be able</th>\n",
       "      <th>...</th>\n",
       "      <th>voters</th>\n",
       "      <th>votes</th>\n",
       "      <th>want</th>\n",
       "      <th>want to</th>\n",
       "      <th>was</th>\n",
       "      <th>way</th>\n",
       "      <th>way to</th>\n",
       "      <th>ways</th>\n",
       "      <th>we</th>\n",
       "      <th>we can</th>\n",
       "      <th>we should</th>\n",
       "      <th>well</th>\n",
       "      <th>were</th>\n",
       "      <th>what</th>\n",
       "      <th>what they</th>\n",
       "      <th>when</th>\n",
       "      <th>when you</th>\n",
       "      <th>where</th>\n",
       "      <th>which</th>\n",
       "      <th>while</th>\n",
       "      <th>who</th>\n",
       "      <th>why</th>\n",
       "      <th>will</th>\n",
       "      <th>will be</th>\n",
       "      <th>with</th>\n",
       "      <th>with the</th>\n",
       "      <th>without</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>would be</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>you are</th>\n",
       "      <th>you can</th>\n",
       "      <th>you have</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.955270</td>\n",
       "      <td>2.675781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.445918</td>\n",
       "      <td>2.638084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.440250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.789292</td>\n",
       "      <td>2.859709</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.951207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.544805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.340838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.585469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.497354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.192727</td>\n",
       "      <td>2.225022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.254240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.607026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.130157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.445918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.867196</td>\n",
       "      <td>7.700808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.231589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.578584</td>\n",
       "      <td>2.859709</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16.112173</td>\n",
       "      <td>6.086583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.807921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.384413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.861823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.596363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.651757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.822185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.565078</td>\n",
       "      <td>2.908467</td>\n",
       "      <td>1.445918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.867196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.220125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.364978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.272324</td>\n",
       "      <td>1.670572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.231589</td>\n",
       "      <td>2.476658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.894646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.259636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.807921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.650873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.723646</td>\n",
       "      <td>4.181465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.542404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.323337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.082399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.651757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.675507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.275265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.220125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.364978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.683938</td>\n",
       "      <td>2.859709</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.160966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.259636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.603492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.614378</td>\n",
       "      <td>2.610741</td>\n",
       "      <td>6.243385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.525812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.651757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.825125</td>\n",
       "      <td>3.130157</td>\n",
       "      <td>2.908467</td>\n",
       "      <td>1.445918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.568816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.440250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.54328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.00235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.231589</td>\n",
       "      <td>2.476658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.894646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.87657</td>\n",
       "      <td>16.112173</td>\n",
       "      <td>3.043291</td>\n",
       "      <td>16.362012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.301746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.774841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.637163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  able to     about  about the  ...   you can  you have  young       your\n",
       "0   0.0      0.0  4.955270   2.675781  ...  0.000000       0.0    0.0   0.000000\n",
       "1   0.0      0.0  6.607026   0.000000  ...  0.000000       0.0    0.0   0.000000\n",
       "2   0.0      0.0  1.651757   0.000000  ...  8.323337       0.0    0.0  16.082399\n",
       "3   0.0      0.0  1.651757   0.000000  ...  0.000000       0.0    0.0   0.000000\n",
       "4   0.0      0.0  1.651757   0.000000  ...  0.000000       0.0    0.0   0.000000\n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the data into a dataframe\n",
    "transformed_data = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "transformed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the vectorizer for later use\n",
    "with open('../vectorizer.pk','wb') as file:\n",
    "    pickle.dump(vectorizer,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Seeing how different models work with this feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5, max_iter=900, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.5, max_iter=900, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.5, max_iter=900, random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "log_reg = LogisticRegression(penalty='l2',random_state=42,max_iter=900,C=0.5)\n",
    "log_reg.fit(transformed_data.values,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on Training Set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99781706635762"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions on training data and evaluating\n",
    "print('ROC AUC on Training Set:')\n",
    "predictions = log_reg.predict_proba(transformed_data.values)[:,1]\n",
    "roc_auc_score(labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.998733</td>\n",
       "      <td>0.867000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.077472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.998031</td>\n",
       "      <td>0.802032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.998391</td>\n",
       "      <td>0.815302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.816038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.999083</td>\n",
       "      <td>0.935529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999293</td>\n",
       "      <td>0.966099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_score  test_score\n",
       "count     5.000000    5.000000\n",
       "mean      0.998733    0.867000\n",
       "std       0.000516    0.077472\n",
       "min       0.998031    0.802032\n",
       "25%       0.998391    0.815302\n",
       "50%       0.998869    0.816038\n",
       "75%       0.999083    0.935529\n",
       "max       0.999293    0.966099"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation \n",
    "# This will show me how good the model generalizes on the training set distribution\n",
    "# I can get an idea of how well it will do then\n",
    "cross_val_scores = pd.DataFrame(cross_validate(LogisticRegression(penalty='l2',random_state=42,max_iter=900,C=0.5),\n",
    "                                transformed_data.values,labels,scoring='roc_auc',cv=5,return_train_score=True))\n",
    "cross_val_scores[['train_score','test_score']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "with open('../models/tfidf-trained models/log_reg.pkl','wb') as file:\n",
    "    pickle.dump(log_reg,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(min_samples_leaf=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(min_samples_leaf=20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "d_tree = DecisionTreeClassifier(criterion='gini',min_samples_leaf=20)\n",
    "d_tree.fit(transformed_data.values,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on Training Set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9850713017756577"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions on training data and evaluating\n",
    "print('ROC AUC on Training Set:')\n",
    "predictions = d_tree.predict_proba(transformed_data.values)[:,1]\n",
    "roc_auc_score(labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.985957</td>\n",
       "      <td>0.872913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.050421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.983173</td>\n",
       "      <td>0.817527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.984626</td>\n",
       "      <td>0.829144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.986838</td>\n",
       "      <td>0.873998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.987248</td>\n",
       "      <td>0.908240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.987901</td>\n",
       "      <td>0.935655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_score  test_score\n",
       "count     5.000000    5.000000\n",
       "mean      0.985957    0.872913\n",
       "std       0.001984    0.050421\n",
       "min       0.983173    0.817527\n",
       "25%       0.984626    0.829144\n",
       "50%       0.986838    0.873998\n",
       "75%       0.987248    0.908240\n",
       "max       0.987901    0.935655"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation \n",
    "# This will show me how good the model generalizes on the training set distribution\n",
    "# I can get an idea of how well it will do then\n",
    "cross_val_scores = pd.DataFrame(cross_validate(DecisionTreeClassifier(criterion='gini',min_samples_leaf=20),\n",
    "                                transformed_data.values,labels,scoring='roc_auc',cv=5,return_train_score=True))\n",
    "cross_val_scores[['train_score','test_score']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "with open('../models/tfidf-trained models/d_tree.pkl','wb') as file:\n",
    "    pickle.dump(d_tree,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(transformed_data.values,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on Training Set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions on training data and evaluating\n",
    "print('ROC AUC on Training Set:')\n",
    "predictions = random_forest.predict_proba(transformed_data.values)[:,1]\n",
    "roc_auc_score(labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.887465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_score  test_score\n",
       "count          5.0    5.000000\n",
       "mean           1.0    0.948640\n",
       "std            0.0    0.040026\n",
       "min            1.0    0.887465\n",
       "25%            1.0    0.934532\n",
       "50%            1.0    0.962802\n",
       "75%            1.0    0.965085\n",
       "max            1.0    0.993317"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation \n",
    "# This will show me how good the model generalizes on the training set distribution\n",
    "# I can get an idea of how well it will do then\n",
    "cross_val_scores = pd.DataFrame(cross_validate(RandomForestClassifier(random_state=42),\n",
    "                                transformed_data.values,labels,scoring='roc_auc',cv=5,return_train_score=True))\n",
    "cross_val_scores[['train_score','test_score']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "with open('../models/tfidf-trained models/random_forest.pkl','wb') as file:\n",
    "    pickle.dump(random_forest,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost/Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6614737\ttotal: 278ms\tremaining: 27.6s\n",
      "1:\tlearn: 0.6312344\ttotal: 509ms\tremaining: 24.9s\n",
      "2:\tlearn: 0.6032792\ttotal: 683ms\tremaining: 22.1s\n",
      "3:\tlearn: 0.5774462\ttotal: 930ms\tremaining: 22.3s\n",
      "4:\tlearn: 0.5543001\ttotal: 1.25s\tremaining: 23.7s\n",
      "5:\tlearn: 0.5329778\ttotal: 1.5s\tremaining: 23.5s\n",
      "6:\tlearn: 0.5142026\ttotal: 1.67s\tremaining: 22.2s\n",
      "7:\tlearn: 0.4963277\ttotal: 1.86s\tremaining: 21.4s\n",
      "8:\tlearn: 0.4796403\ttotal: 2.1s\tremaining: 21.2s\n",
      "9:\tlearn: 0.4643784\ttotal: 2.31s\tremaining: 20.8s\n",
      "10:\tlearn: 0.4505088\ttotal: 2.5s\tremaining: 20.2s\n",
      "11:\tlearn: 0.4370316\ttotal: 2.7s\tremaining: 19.8s\n",
      "12:\tlearn: 0.4256112\ttotal: 2.9s\tremaining: 19.4s\n",
      "13:\tlearn: 0.4142865\ttotal: 3.1s\tremaining: 19s\n",
      "14:\tlearn: 0.4040846\ttotal: 3.32s\tremaining: 18.8s\n",
      "15:\tlearn: 0.3948493\ttotal: 3.47s\tremaining: 18.2s\n",
      "16:\tlearn: 0.3862387\ttotal: 3.64s\tremaining: 17.8s\n",
      "17:\tlearn: 0.3772845\ttotal: 3.82s\tremaining: 17.4s\n",
      "18:\tlearn: 0.3693770\ttotal: 4.03s\tremaining: 17.2s\n",
      "19:\tlearn: 0.3619550\ttotal: 4.24s\tremaining: 16.9s\n",
      "20:\tlearn: 0.3551087\ttotal: 4.41s\tremaining: 16.6s\n",
      "21:\tlearn: 0.3482792\ttotal: 4.77s\tremaining: 16.9s\n",
      "22:\tlearn: 0.3428427\ttotal: 4.91s\tremaining: 16.5s\n",
      "23:\tlearn: 0.3379920\ttotal: 5.1s\tremaining: 16.2s\n",
      "24:\tlearn: 0.3332427\ttotal: 5.22s\tremaining: 15.7s\n",
      "25:\tlearn: 0.3278369\ttotal: 5.43s\tremaining: 15.5s\n",
      "26:\tlearn: 0.3226482\ttotal: 5.6s\tremaining: 15.1s\n",
      "27:\tlearn: 0.3182460\ttotal: 5.8s\tremaining: 14.9s\n",
      "28:\tlearn: 0.3142090\ttotal: 5.95s\tremaining: 14.6s\n",
      "29:\tlearn: 0.3103083\ttotal: 6.15s\tremaining: 14.4s\n",
      "30:\tlearn: 0.3059023\ttotal: 6.29s\tremaining: 14s\n",
      "31:\tlearn: 0.3017793\ttotal: 6.47s\tremaining: 13.7s\n",
      "32:\tlearn: 0.2977899\ttotal: 6.66s\tremaining: 13.5s\n",
      "33:\tlearn: 0.2940394\ttotal: 6.91s\tremaining: 13.4s\n",
      "34:\tlearn: 0.2908471\ttotal: 7.07s\tremaining: 13.1s\n",
      "35:\tlearn: 0.2870206\ttotal: 7.37s\tremaining: 13.1s\n",
      "36:\tlearn: 0.2836560\ttotal: 7.53s\tremaining: 12.8s\n",
      "37:\tlearn: 0.2797922\ttotal: 7.69s\tremaining: 12.5s\n",
      "38:\tlearn: 0.2767795\ttotal: 7.84s\tremaining: 12.3s\n",
      "39:\tlearn: 0.2743376\ttotal: 8.02s\tremaining: 12s\n",
      "40:\tlearn: 0.2718216\ttotal: 8.14s\tremaining: 11.7s\n",
      "41:\tlearn: 0.2687082\ttotal: 8.35s\tremaining: 11.5s\n",
      "42:\tlearn: 0.2652715\ttotal: 8.59s\tremaining: 11.4s\n",
      "43:\tlearn: 0.2625951\ttotal: 8.72s\tremaining: 11.1s\n",
      "44:\tlearn: 0.2600998\ttotal: 8.87s\tremaining: 10.8s\n",
      "45:\tlearn: 0.2573826\ttotal: 9.12s\tremaining: 10.7s\n",
      "46:\tlearn: 0.2545126\ttotal: 9.26s\tremaining: 10.4s\n",
      "47:\tlearn: 0.2523613\ttotal: 9.52s\tremaining: 10.3s\n",
      "48:\tlearn: 0.2501209\ttotal: 9.78s\tremaining: 10.2s\n",
      "49:\tlearn: 0.2479995\ttotal: 9.95s\tremaining: 9.95s\n",
      "50:\tlearn: 0.2460456\ttotal: 10.1s\tremaining: 9.7s\n",
      "51:\tlearn: 0.2435715\ttotal: 10.3s\tremaining: 9.48s\n",
      "52:\tlearn: 0.2416863\ttotal: 10.4s\tremaining: 9.22s\n",
      "53:\tlearn: 0.2397614\ttotal: 10.5s\tremaining: 8.98s\n",
      "54:\tlearn: 0.2376153\ttotal: 10.7s\tremaining: 8.76s\n",
      "55:\tlearn: 0.2357080\ttotal: 11s\tremaining: 8.66s\n",
      "56:\tlearn: 0.2334898\ttotal: 11.2s\tremaining: 8.42s\n",
      "57:\tlearn: 0.2315553\ttotal: 11.3s\tremaining: 8.19s\n",
      "58:\tlearn: 0.2299829\ttotal: 11.4s\tremaining: 7.96s\n",
      "59:\tlearn: 0.2282633\ttotal: 11.6s\tremaining: 7.73s\n",
      "60:\tlearn: 0.2262202\ttotal: 11.7s\tremaining: 7.51s\n",
      "61:\tlearn: 0.2240925\ttotal: 11.9s\tremaining: 7.28s\n",
      "62:\tlearn: 0.2221309\ttotal: 12.2s\tremaining: 7.14s\n",
      "63:\tlearn: 0.2206224\ttotal: 12.3s\tremaining: 6.91s\n",
      "64:\tlearn: 0.2191157\ttotal: 12.6s\tremaining: 6.76s\n",
      "65:\tlearn: 0.2175623\ttotal: 12.7s\tremaining: 6.55s\n",
      "66:\tlearn: 0.2159999\ttotal: 12.9s\tremaining: 6.36s\n",
      "67:\tlearn: 0.2143209\ttotal: 13.1s\tremaining: 6.15s\n",
      "68:\tlearn: 0.2125711\ttotal: 13.2s\tremaining: 5.93s\n",
      "69:\tlearn: 0.2111659\ttotal: 13.3s\tremaining: 5.71s\n",
      "70:\tlearn: 0.2097681\ttotal: 13.5s\tremaining: 5.51s\n",
      "71:\tlearn: 0.2081573\ttotal: 13.7s\tremaining: 5.31s\n",
      "72:\tlearn: 0.2069303\ttotal: 13.8s\tremaining: 5.11s\n",
      "73:\tlearn: 0.2054259\ttotal: 14s\tremaining: 4.91s\n",
      "74:\tlearn: 0.2041005\ttotal: 14.1s\tremaining: 4.71s\n",
      "75:\tlearn: 0.2027546\ttotal: 14.3s\tremaining: 4.52s\n",
      "76:\tlearn: 0.2015353\ttotal: 14.6s\tremaining: 4.35s\n",
      "77:\tlearn: 0.2003643\ttotal: 14.8s\tremaining: 4.18s\n",
      "78:\tlearn: 0.1991244\ttotal: 14.9s\tremaining: 3.97s\n",
      "79:\tlearn: 0.1977070\ttotal: 15.1s\tremaining: 3.77s\n",
      "80:\tlearn: 0.1966214\ttotal: 15.2s\tremaining: 3.58s\n",
      "81:\tlearn: 0.1955405\ttotal: 15.4s\tremaining: 3.38s\n",
      "82:\tlearn: 0.1944574\ttotal: 15.6s\tremaining: 3.19s\n",
      "83:\tlearn: 0.1934162\ttotal: 15.7s\tremaining: 2.99s\n",
      "84:\tlearn: 0.1923197\ttotal: 16s\tremaining: 2.82s\n",
      "85:\tlearn: 0.1913275\ttotal: 16.1s\tremaining: 2.62s\n",
      "86:\tlearn: 0.1900099\ttotal: 16.4s\tremaining: 2.45s\n",
      "87:\tlearn: 0.1891391\ttotal: 16.6s\tremaining: 2.27s\n",
      "88:\tlearn: 0.1881004\ttotal: 16.8s\tremaining: 2.08s\n",
      "89:\tlearn: 0.1869974\ttotal: 16.9s\tremaining: 1.88s\n",
      "90:\tlearn: 0.1861492\ttotal: 17.1s\tremaining: 1.69s\n",
      "91:\tlearn: 0.1849539\ttotal: 17.2s\tremaining: 1.5s\n",
      "92:\tlearn: 0.1841845\ttotal: 17.4s\tremaining: 1.31s\n",
      "93:\tlearn: 0.1832984\ttotal: 17.5s\tremaining: 1.12s\n",
      "94:\tlearn: 0.1824189\ttotal: 17.7s\tremaining: 930ms\n",
      "95:\tlearn: 0.1815335\ttotal: 17.9s\tremaining: 747ms\n",
      "96:\tlearn: 0.1804596\ttotal: 18.1s\tremaining: 559ms\n",
      "97:\tlearn: 0.1796551\ttotal: 18.3s\tremaining: 373ms\n",
      "98:\tlearn: 0.1788825\ttotal: 18.5s\tremaining: 187ms\n",
      "99:\tlearn: 0.1779742\ttotal: 18.7s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x166420b20>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "catboost_clf = CatBoostClassifier(iterations=100,learning_rate=0.03,loss_function='Logloss',random_seed=42)\n",
    "catboost_clf.fit(transformed_data.values,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on Training Set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9879435864950069"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions on training data and evaluating\n",
    "print('ROC AUC on Training Set:')\n",
    "predictions = catboost_clf.predict_proba(transformed_data.values)[:,1]\n",
    "roc_auc_score(labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "catboost_clf.save_model('../models/tfidf-trained models/catboost_clf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways:\n",
    "\n",
    "TFIDF did a little bit better than my features. However, the models didn't perform that much better. Only better by 0.02. What if I try combing my features with the TFIDF features? What results will I get? What if I increase the TFIDF from 500 features to 750? What if I make the n-grams 3 to 5 like many notebooks have? Worthy experiments to run along with running deep learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "authentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
